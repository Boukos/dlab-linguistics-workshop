{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pirahã syntax\n",
    "\n",
    "In this notebook we are going to explore Pirahã syntax. As you know, Pirahã is (in)famous in the field of linguistics for many reasons. One of the most prominent claims made about the language is a lack of syntactic recursion. Futrell et al. (2016) analyze a corpus of Pirahã for evidence of syntactic embedding. They report that they do not find any such evidence, and that the corpus is consistent with an analysis of Pirahã as a [regular language](https://en.wikipedia.org/wiki/Regular_language). If you want to know more about Pirahã and the controversy surrounding it, read the following:\n",
    "\n",
    "- Everett, Daniel L. \"Pirahã culture and grammar: a response to some criticisms.\" Language 85.2 (2009): 405-442.\n",
    "- Everett, Daniel, et al. \"Cultural constraints on grammar and cognition in Piraha: Another look at the design features of human language.\" Current anthropology 46.4 (2005): 621-646.\n",
    "- Frank, Michael C., et al. \"Number as a cognitive technology: Evidence from Pirahã language and cognition.\" Cognition 108.3 (2008): 819-824.\n",
    "- Futrell, Richard, et al. \"A corpus investigation of syntactic embedding in Pirahã.\" PloS one 11.3 (2016): e0145289.\n",
    "- Nevins, Andrew, David Pesetsky, and Cilene Rodrigues. \"Pirahã exceptionality: A reassessment.\" Language 85.2 (2009): 355-404.\n",
    "\n",
    "Throughout all the notebooks of this workshop, we're not going to be concerned with whether the arguments are right or wrong. Rather, we care about practising our Python skills so that we can do similar linguistic analyses. In particular, in this notebook we're going to practice the following topics:\n",
    "\n",
    "### Core ideas of this notebook\n",
    "- Object types\n",
    "- Manipulating text data\n",
    "- Regular expressions\n",
    "- User-defined functions\n",
    "- Writing modular code\n",
    "- Documentation\n",
    "- Going from messy to structured data\n",
    "- Using other people's code\n",
    "\n",
    "### You will learn\n",
    "- File input/output\n",
    "- String methods\n",
    "- String slicing\n",
    "- Regular expressions\n",
    "- ...\n",
    "\n",
    "### Our goal\n",
    "We want to turn <a href=\"data/piraha.txt\">this</a> into this:\n",
    "\n",
    "|   | story_num | speaker | fname                                  | utt_num | utt_translation                                          | sent_num | sent_translation                          |                                        |\n",
    "|---|-----------|---------|----------------------------------------|---------|----------------------------------------------------------|----------|-------------------------------------------|----------------------------------------|\n",
    "| 0 | 1         | Aogioso | 01_KATO'S BABY FALLS NEAR THE FIRE.pdf | 2       | He (TixohOI) fell by the fire.                           | 1        | \"He [TixohOI                              | KatO's baby] almost fell in the fire.\" |\n",
    "| 1 | 1         | Aogioso | 01_KATO'S BABY FALLS NEAR THE FIRE.pdf | 3       | I spoke (carried sound). TixohOI is crying on the ground | 1        | I spoke!                                  |                                        |\n",
    "| 2 | 1         | Aogioso | 01_KATO'S BABY FALLS NEAR THE FIRE.pdf | 3       | I spoke (carried sound). TixohOI is crying on the ground | 2        | \"\"\"He [TixohOI] is on the ground.\"\"\"      |                                        |\n",
    "| 3 | 1         | Aogioso | 01_KATO'S BABY FALLS NEAR THE FIRE.pdf | 3       | I spoke (carried sound). TixohOI is crying on the ground | 3        | \"\"\"TixohOI is crying.\"\"\"                  |                                        |\n",
    "| 4 | 1         | Aogioso | 01_KATO'S BABY FALLS NEAR THE FIRE.pdf | 4       | He fell by the fire right now.                           | 1        | [He] certainly fell by the fire just now. |                                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The corpus used in the paper consists of Pirahã stories that were originally collected and translated by Steve Sheldon and Dan Everett over the period of several decades. It also includes aligned translation between Pirahã\n",
    "and English, including shallow syntactic parses and approximate English glosses.\n",
    "\n",
    "Here's how the authors describe the way they created the corpus:\n",
    "> We obtained glossed transcriptions of 17 stories in Pirahã, consisting of a total of 1149 sentences\n",
    "and 6830 words in our analysis. 13 of the stories were collected by Steve Sheldon in the\n",
    "1970s, and the remaining 4 stories were collected by Dan Everett over the period 1980–2009.\n",
    "Each story was told by a single speaker with no recorded interruptions. The stories were transcribed\n",
    "by Everett or Sheldon; audio recordings are only available for stories 2 and 3. According\n",
    "to Everett, the texts are fairly representative of how the Pirahã tell stories to one another.\n",
    "\n",
    "If you're interested, you can see all the original texts in pdf format [here](https://github.com/languageMIT/piraha/tree/master/sources)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Downloading the data\n",
    "\n",
    "Futrell et al. make their data [available](https://github.com/languageMIT/piraha), but I've already downloaded it for you. In the `data` folder there's a file called `piraha.txt`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the data\n",
    "\n",
    "Although it's great that the data is made freely available, it's in a really messy format. It's going to take some preprocessing for us to reformat the data into a more usable form. Here's the description from the [README](https://github.com/languageMIT/piraha/blob/master/README.md) of how the corpus is structured:\n",
    "\n",
    "> Each text in the corpus is preceded by three lines of hashes and information about the source of the text. The corpus is divided into stories; stories are divided into \"utterances\"; and utterances are divided into sentences. Utterances correspond to the sentence breaks in Steve Sheldon's original glosses. Each utterance is preceded by two English glosses (free translations). The first is labeled with a hash and a code of two numbers, and reflects the English translation given by Steve Sheldon or Daniel L. Everett in their original translation. The second is labeled with a hash and a code of three numbers, and reflects the current best translation, as judged by Daniel L. Everett, Steve Sheldon, and the other authors. Clarifications are provided in square brackets in these glosses. The glosses allow simple text searching to find rough equivalents of English words and phrases (e.g. what does Pirahã use to convey meanings glossed as \"and\"?).\n",
    "\n",
    "> Each Pirahã sentence is labeled with a unique code of three numbers, appearing on the preceding line along with its current best English translation. The first number indicates the text in which the utterance appears. The second number indicates the utterance's sequential placement within the text. This second number reflects the utterance boundaries present in the original transcriptions (e.g. by Dan Everett and Steve Sheldon). In many cases, text which was originally translated into a single utterance actually includes a group of Pirahã sentences according to our current best translations. When this occurs, the third number indicates the order of the Pirahã sentences within this grouping. Otherwise, the third number is simply 1.\n",
    "\n",
    "Here's my simplification of it:\n",
    "\n",
    "- The corpus is all in one file, `piraha.txt`.\n",
    "- There are 17 stories in the corpus. They are separated from one another by three lines of hashtags.\n",
    "- Each story starts with three pieces of metadata: the source, the informant and the comment.\n",
    "- The source holds the names of the original pdf files of the story and the story number.\n",
    "- The informant is the speaker (for most stories there's only one speaker).\n",
    "- The comment holds various other things, like background, summary of the story, etc.\n",
    "- After the metadata, each story has a series of utterances. Utterances are the original sentence boundaries given by either Everett or Sheldon. Each utterance has a number within the story (e.g. 4.16 for utterance number 16 in story number 4). Immediately after the numeric identifier comes the original English translation of the utterance.\n",
    "- However, Sheldon and Everett have re-analyzed many utterances to in fact consist of more than one sentence. So each utterance actually consists of one or more sentences. Each sentence is identified by the story number, utterance number and sentence number (so 4.16.2 is the 2nd sentence of the 16th utterance of the 4th text). Immediately after each numeric identifier of a sentence is a shallow parse tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the data\n",
    "_Hint: It's sorted in a file called 'piraha.txt' in a folder called 'data'._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILL IN THE BLANKS\n",
    "fname = 'data/piraha.txt'\n",
    "with open(fname, 'r') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What type is `fname`?\n",
    "- What type is `open(fname)`?\n",
    "- Can you access the opened file after the `with` statement?\n",
    "- Old school way of opening files\n",
    "- Joining paths together\n",
    "- Finding the type of a file\n",
    "- Reading in files line by line\n",
    "- Read Python docs for [open](https://docs.python.org/3/library/functions.html) and [os.path](https://docs.python.org/3/library/os.path.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split `raw_text` into individual stories\n",
    "\n",
    "_Hint: Each text is separated by a special string. Use that to turn `raw_text` into a list of stories._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### FILL IN THE BLANKS\n",
    "text_boundary = '''############################################################################################################################################ \n",
    "############################################################################################################################################ \n",
    "############################################################################################################################################'''\n",
    "stories = raw_text.split(text_boundary)[1:]\n",
    "stories = [story.strip() for story in stories]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What type is `stories`?\n",
    "- How can you get the first story?\n",
    "- What type is each story?\n",
    "- How can you get the first 100 characters of the seventh story?\n",
    "- What does `strip()` [do](https://docs.python.org/3.6/library/stdtypes.html#text-sequence-type-str)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Turn what you just did in 2 into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_stories(text):\n",
    "    \"\"\"Return all the stories in `text`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The raw text of the corpus\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    stories: list(str)\n",
    "    \"\"\"\n",
    "    text_boundary = '''############################################################################################################################################ \n",
    "############################################################################################################################################ \n",
    "############################################################################################################################################'''\n",
    "    stories = text.split(text_boundary)[1:]\n",
    "    return [story.strip() for story in stories]\n",
    "\n",
    "stories = split_stories(raw_text)\n",
    "story = stories[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does the function `split_stories`'s parameter have the name you gave it?\n",
    "- Do user-defined functions have to have parameters?\n",
    "- If you forget the `return` statement, what does the function return?\n",
    "- Why do we bother ever defining functions?\n",
    "- Lambda functions\n",
    "- Higher-order functions (e.g. for `sorted`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Import the library for regular expressions in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILL IN THE BLANKS\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why do we have to import libraries at all? Wouldn't it be easier if everything was immediately available like the `open` function is?\n",
    "- What type is the module?\n",
    "- What if we really wanted to have our own variable with the same name as a library we import? Won't their names clash?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extract the story number from a story\n",
    "\n",
    "_Hint: Look in `piraha.txt` to see that a story's number is stored on the line that starts with \"# SOURCE\". What is the regular expression for a single digit?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match = re.search(r'# SOURCE: (\\d+)', story)\n",
    "if match:\n",
    "    number = match.group(1)\n",
    "    number = int(number)\n",
    "else:\n",
    "    number = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Now turn what you did in 5 into a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How do we access the function called `search` in the `re` module?\n",
    "- What if we had imported everything from the `re` module like this: `from re import *`?\n",
    "- What parameters does the `search` function take?\n",
    "- What's the difference between `search` and `match`?\n",
    "- What type of object does the `re.search` function return if it does find a match? What if it doesn't?\n",
    "- How can I turn something of type `int` into a string? How can I turn a string into an integer?\n",
    "- Use [pythex](https://pythex.org/) to check your regexes\n",
    "- Compiling regexes in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILL IN THE BLANKS\n",
    "def story_number(story):\n",
    "    \"\"\"Extract the number of `story`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    story : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    number: int\n",
    "        The position of the story in the corpus\n",
    "    \"\"\"\n",
    "    match = re.search(r'# SOURCE: (\\d+)', story)\n",
    "    if match:\n",
    "        number = match.group(1)\n",
    "        number = int(number)\n",
    "        return number\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What type is `story_number`?\n",
    "- Function documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define functions for extracting the filename, speaker and comment from a story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILL IN THE BLANKS\n",
    "def story_filename(story):\n",
    "    \"\"\"Extract the original pdf filename of `story`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    story : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    filename: str\n",
    "    \"\"\"\n",
    "    match = re.search(r'# SOURCE: .*, (.*.*\\.pdf)', story)\n",
    "    if match:\n",
    "        filename = match.group(1)\n",
    "        return filename\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILL IN THE BLANKS\n",
    "def story_informant(story):\n",
    "    \"\"\"Extract the name of the speaker of `story`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    story : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    name: str\n",
    "    \"\"\"\n",
    "    speaker_pattern = re.compile(r'# INFORMANT: (.*)\\n')\n",
    "    match = re.search(speaker_pattern, story)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILL IN THE BLANKS\n",
    "def story_comment(story):\n",
    "    \"\"\"_____\"\"\"\n",
    "    speaker_pattern = re.compile(r'# COMMENT: (.*)\\n')\n",
    "    match = re.search(speaker_pattern, story)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Split a story into a list of its utterances\n",
    "\n",
    "_Hint: Looking at the file 'piraha.txt' again, note that within each story, there are blocks of data separated by newlines. Each block is an utterance. We want a function that takes in a story (what type will this be?) and returns a list of utterances (i.e. a list of those blocks). A newline is represented as the sequence '\\n' in Python._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_utterances(story):\n",
    "    \"\"\"Return all the utterances in `story`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    story : str\n",
    "        The raw text of a story\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    utterances: list(str)\n",
    "    \"\"\"\n",
    "    utterance_boundary = '\\n\\n'\n",
    "    utterances = story.split(utterance_boundary)[1:]\n",
    "    first_utterance = utterances[0]\n",
    "    if first_utterance.startswith('### NOTE'):\n",
    "        first_utterance = re.sub('### NOTE.*\\n', '', first_utterance)\n",
    "    utterances = [first_utterance] + utterances[1:]\n",
    "    return utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If '\\n' is a newline, what is a tab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Extract the utterance number and the translation\n",
    "\n",
    "_Hint: In an utterance, the first line always consists of the number and the translation (in English). The number is of the form \"x.y\", where \"x\" is the story number, and \"y\" is the utterance number (we just want the utterance number). The translation is everything after the \":\" after the number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utterance_number(utt):\n",
    "    \"\"\"Extract the number of `utt`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    utt : str\n",
    "        An utterance\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    number: int\n",
    "        The position of the utterance in the story\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d+\\.\\d+):', utt)\n",
    "    if match:\n",
    "        whole_number = match.group(1)\n",
    "        number = whole_number.split('.')[1]\n",
    "        number = int(number)\n",
    "        return number\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utterance_translation(utt):\n",
    "    \"\"\"Extract the (original) translation of `utt`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    utt : str\n",
    "        An utterance\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    translation: str\n",
    "        The translation of the utterance\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d+\\.\\d+): (.*)', utt)\n",
    "    if match:\n",
    "        translation = match.group(2)\n",
    "        return translation\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Split an utterance into its sentences\n",
    "\n",
    "_Hint: Within an utterance, after the first line containing the number of English translation, there are one or more sentences. We want a function to takes an utterance and returns a list of sentences._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_sentences(utt):\n",
    "    \"\"\"Return all the sentences in `utterance`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    utt : str\n",
    "        The raw text of an utterance\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sentences: list(str)\n",
    "    \"\"\"\n",
    "    all_sentences = re.sub(r'(# \\d+\\.\\d+): (.*)', '', utt).strip()\n",
    "    sentences = re.split(r'(?: ^|\\n)# ', all_sentences)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Extract the sentence number and translation\n",
    "\n",
    "_Hint: Every sentence starts with the number in the form of \"x.y.z\", where \"x\" is the story number, \"y\" is the utterance number, and \"z\" is the sentence number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_number(sent):\n",
    "    \"\"\"Extract the number of `sent`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sent : str\n",
    "        A sentence\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    number: int\n",
    "        The position of the sentence in the utterance\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d+\\.\\d+\\.\\d+):', sent)\n",
    "    if match:\n",
    "        whole_number = match.group(1)\n",
    "        number = whole_number.split('.')[2]\n",
    "        number = int(number)\n",
    "        return number\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_translation(sent):\n",
    "    \"\"\"Extract the translation of `sent`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sent : str\n",
    "        An utterance\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    translation: str\n",
    "        The translation of the sent\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d+\\.\\d+\\.\\d+): (.*)', sent)\n",
    "    if match:\n",
    "        translation = match.group(2)\n",
    "        return translation\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tree import ParentedTree\n",
    "from nltk.tgrep import tgrep_nodes, tgrep_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tree(sent):\n",
    "    \"\"\"Extract the tree of `sent`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sent : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tree: str\n",
    "    \"\"\"\n",
    "    try:\n",
    "        non_tree_pattern = re.compile(r'(?:# )?\\d+\\.\\d+(\\.\\d+)?: .*')\n",
    "        tree = re.sub(non_tree_pattern, '', sent).strip()\n",
    "        tree = re.sub(r'#.*', '', tree).strip()\n",
    "        return ParentedTree.fromstring(tree)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_from_tree(t):\n",
    "    \"\"\"Return list of words from tree `t`.\"\"\"\n",
    "    if t:\n",
    "        return [leaf.split('/')[0] for leaf in t.leaves()]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_num</th>\n",
       "      <th>speaker</th>\n",
       "      <th>fname</th>\n",
       "      <th>utt_num</th>\n",
       "      <th>utt_translation</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>sent_translation</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Aogioso</td>\n",
       "      <td>01_KATO'S BABY FALLS NEAR THE FIRE.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>Early in the day I spoke. BaIgipOhoasi spoke (...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Early in the] day I spoke.</td>\n",
       "      <td>[ti, xahoa, -gI, ti, iga, O, -p, -I, -xi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aogioso</td>\n",
       "      <td>01_KATO'S BABY FALLS NEAR THE FIRE.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>Early in the day I spoke. BaIgipOhoasi spoke (...</td>\n",
       "      <td>2</td>\n",
       "      <td>BaIgipOhoasi [speaker's sister] spoke.</td>\n",
       "      <td>[hi, igA, xai, baIgipOhoasi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Aogioso</td>\n",
       "      <td>01_KATO'S BABY FALLS NEAR THE FIRE.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>Early in the day I spoke. BaIgipOhoasi spoke (...</td>\n",
       "      <td>3</td>\n",
       "      <td>\"Is Kato sleepy?\"  [Lit: \"Kato-- her eyes flut...</td>\n",
       "      <td>[KatO, hi, o, *, -b, -a, -p, -I, -aag, -oxoihI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Aogioso</td>\n",
       "      <td>01_KATO'S BABY FALLS NEAR THE FIRE.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>He (TixohOI) fell by the fire.</td>\n",
       "      <td>1</td>\n",
       "      <td>He [TixohOI, KatO's baby] almost fell in the f...</td>\n",
       "      <td>[hi, hoaI, ib, -a, -b, -og, -aA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Aogioso</td>\n",
       "      <td>01_KATO'S BABY FALLS NEAR THE FIRE.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>I spoke (carried sound). TixohOI is crying on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I spoke!</td>\n",
       "      <td>[ti, igA, xai, -ai]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_num  speaker                                   fname  utt_num  \\\n",
       "0          1  Aogioso  01_KATO'S BABY FALLS NEAR THE FIRE.pdf        1   \n",
       "1          1  Aogioso  01_KATO'S BABY FALLS NEAR THE FIRE.pdf        1   \n",
       "2          1  Aogioso  01_KATO'S BABY FALLS NEAR THE FIRE.pdf        1   \n",
       "3          1  Aogioso  01_KATO'S BABY FALLS NEAR THE FIRE.pdf        2   \n",
       "4          1  Aogioso  01_KATO'S BABY FALLS NEAR THE FIRE.pdf        3   \n",
       "\n",
       "                                     utt_translation  sent_num  \\\n",
       "0  Early in the day I spoke. BaIgipOhoasi spoke (...         1   \n",
       "1  Early in the day I spoke. BaIgipOhoasi spoke (...         2   \n",
       "2  Early in the day I spoke. BaIgipOhoasi spoke (...         3   \n",
       "3                     He (TixohOI) fell by the fire.         1   \n",
       "4  I spoke (carried sound). TixohOI is crying on ...         1   \n",
       "\n",
       "                                    sent_translation  \\\n",
       "0                        [Early in the] day I spoke.   \n",
       "1             BaIgipOhoasi [speaker's sister] spoke.   \n",
       "2  \"Is Kato sleepy?\"  [Lit: \"Kato-- her eyes flut...   \n",
       "3  He [TixohOI, KatO's baby] almost fell in the f...   \n",
       "4                                           I spoke!   \n",
       "\n",
       "                                               words  \n",
       "0          [ti, xahoa, -gI, ti, iga, O, -p, -I, -xi]  \n",
       "1                       [hi, igA, xai, baIgipOhoasi]  \n",
       "2  [KatO, hi, o, *, -b, -a, -p, -I, -aag, -oxoihI...  \n",
       "3                   [hi, hoaI, ib, -a, -b, -og, -aA]  \n",
       "4                                [ti, igA, xai, -ai]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentences = []\n",
    "for story in split_stories(raw_text):\n",
    "    for utterance in split_utterances(story):\n",
    "        for sentence in split_sentences(utterance):\n",
    "            dictionary = {}\n",
    "            dictionary['story_num'] = story_number(story)\n",
    "            dictionary['fname'] = story_filename(story)\n",
    "            dictionary['speaker'] = story_informant(story)\n",
    "            #dictionary['comment'] = story_comment(story)\n",
    "            dictionary['utt_num'] = utterance_number(utterance)\n",
    "            dictionary['utt_translation'] = utterance_translation(utterance)\n",
    "            dictionary['sent_num'] = sentence_number(sentence)\n",
    "            dictionary['sent_translation'] = sentence_translation(sentence)\n",
    "            #dictionary['sent_tree'] = sentence_tree(sentence)\n",
    "            dictionary['words'] = words_from_tree(sentence_tree(sentence))\n",
    "            sentences.append(dictionary)\n",
    "\n",
    "corpus = pd.DataFrame(sentences)\n",
    "columns = ['story_num', 'speaker', 'fname', 'utt_num', 'utt_translation', 'sent_num', 'sent_translation', 'words']\n",
    "corpus = corpus[columns]\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Verify the following\n",
    "> The phonological segments of Pirahã are /i/, /a/, /u/, /p/, /t/, /k/, /h/, /s/, /b/, /g/, and /ʔ/. In the orthography we adopt for this paper, < x > represents the glottal stop and < o > represents /u/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The language has two tones, high and low. Note that in this corpus high tones are marked with a capitalized letter. Once you've verified this, change all high tones to the IPA vowel with an accute accent, and low vowels to the IPA vowel with grave accent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The sound /s/ is usually absent from women’s speech; women use /h/ where men use /s/. Can you infer which speakers are female and which are male?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Check overview\n",
    "- The word order in Pirahã is predominantly verb-final, with subjects (S) usually preceding objects (O) for a predominantly SOV word order\n",
    "- For example, if the subject intervened between the object and the verb (as in an OSV order), the object was labeled as a topic-obj. Similarly, noun phrases appearing after the verb were labeled as topics\n",
    "- We used labels similar to the Penn Treebank labels for syntactic categories [40]: NP (noun phrase); IN (adposition); PP (adpositional phrase); VP (verb phrase); S (sentence); NN (a common noun); PRP (pronoun); NNP (proper noun); POS (possessive NP); JJ (adjective); DT (determiner); CD (quantity term); RB (adverb); FW (foreign word); FRAG (fragment). We also introduced the symbol Q dominating the contents of direct speech reports\n",
    "- Note that in this corpus high tones are marked with a capitalized letter.\n",
    "- 1149 sentences, with an average of 5.9 words per sentence. But also contains original sentence boundaries, making 749 sentences.\n",
    "- Shallow POS was added, and grammatical relations (subject, object, indirect object, locative, temporal, instrumental, vocative, topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
